configfile: "config/config.yaml"
threads: 1
# -----------------------------------------------------------------------------
# Setup
# -----------------------------------------------------------------------------
PATHS=config['paths']
DATASET = os.path.splitext(os.path.basename(PATHS["dataset"]))[0]
REPRESENTATIONS = config["representations"]
FOLDS = config["folds"]
ENUM_FACTORS = config["enum_factors"]
OUTPUT_DIR = PATHS['output_dir']

shell.executable("/bin/bash")

wildcard_constraints:
    dataset=DATASET,
    repr='|'.join(REPRESENTATIONS),
    fold='\d+'

# -----------------------------------------------------------------------------

# -----------------------------------------------------------------------------
# Rules
# -----------------------------------------------------------------------------
rule plots:
    input:
        topk=expand(f"{OUTPUT_DIR}/model_evaluation/plot/{{enum_factor}}/topk",
            enum_factor=ENUM_FACTORS),
        calculate_outcomes_plot=expand(f"{OUTPUT_DIR}/model_evaluation/plot/{{enum_factor}}/calculate_outcomes",
            enum_factor=ENUM_FACTORS),
        nn_tc_plot=expand(f"{OUTPUT_DIR}/model_evaluation/plot/{{enum_factor}}/write_nn_tc",
            enum_factor=ENUM_FACTORS),
        train_discriminator_plot=expand(f"{OUTPUT_DIR}/model_evaluation/plot/{{enum_factor}}/train_discriminator",
            enum_factor=ENUM_FACTORS),
        freq_distribution_plot=expand(f"{OUTPUT_DIR}/model_evaluation/plot/{{enum_factor}}/freq_distribution",
            enum_factor=ENUM_FACTORS),
        calculate_outcome_distr_plot=expand(f"{OUTPUT_DIR}/model_evaluation/plot/{{enum_factor}}/calculate_outcome_distrs",
            enum_factor=ENUM_FACTORS),
        nn_tc_ever_v_never_plot=expand(f"{OUTPUT_DIR}/model_evaluation/plot/{{enum_factor}}/nn_tc_ever_v_never",
            enum_factor=ENUM_FACTORS),
        topk_tc_plot=expand(f"{OUTPUT_DIR}/model_evaluation/plot/{{enum_factor}}/topk_tc",
            enum_factor=ENUM_FACTORS)


include: "Snakefile_data"

rule calculate_outcomes:
    """
    For sampled smiles in each fold, add a `bin` column denoting what
    frequency bin the sampled smile falls into. And for each bin within that fold,
    calculate certain distribution metrics based on a comparison between
    distribution of sampled smiles and distribution of training smiles in the
    fold.

    `max_molecules` is the max number of sampled smiles to consider for each
    frequency bin.
    """
    conda: "clm"
    input:
        sampled_file=f"{OUTPUT_DIR}/{{enum_factor}}/prior/samples/{{dataset}}_{{repr}}_{{fold}}_unique_masses.csv.gz",
        known_smiles=f"{OUTPUT_DIR}/{{enum_factor}}/prior/samples/known_{{dataset}}_{{repr}}_{{fold}}_unique_masses.csv.gz",
        invalid_smiles=f"{OUTPUT_DIR}/{{enum_factor}}/prior/samples/invalid_{{dataset}}_{{repr}}_{{fold}}_unique_masses.csv.gz",
        train_file=f"{OUTPUT_DIR}/{{enum_factor}}/prior/inputs/train0_{{dataset}}_{{repr}}_{{fold}}.smi",
    output:
        output_file=f"{OUTPUT_DIR}/model_evaluation/{{enum_factor}}/{{dataset}}_{{repr}}_{{fold}}_calculate_outcomes.csv.gz",
    resources:
        mem_mb=256000,
        runtime=1000,
    shell:
        'clm calculate_outcomes '
        '--train_file {input.train_file} '
        '--sampled_file {input.sampled_file} '
        '--known_smiles_file {input.known_smiles} '
        '--invalid_smiles_file {input.invalid_smiles} '
        '--max_molecules 500000 '
        '--seed 12 '
        '--output_file {output.output_file} '


rule plot_calculate_outcomes:
    conda: "clm"
    input:
        expand(f"{OUTPUT_DIR}/model_evaluation/{{enum_factor}}/{{dataset}}_{{repr}}_{{fold}}_calculate_outcomes.csv.gz",
            dataset=DATASET, repr=REPRESENTATIONS, fold=range(FOLDS), allow_missing=True)
    output:
        directory(f"{OUTPUT_DIR}/model_evaluation/plot/{{enum_factor}}/calculate_outcomes"),
    resources:
        mem_mb=256000,
        runtime=1000,
    shell:
        'clm plot calculate_outcomes '
        '--outcome_files {input} '
        '--output_dir {output} '


rule write_nn_tc:
    conda: "clm"
    input:
        query_file=f"{OUTPUT_DIR}/{{enum_factor}}/prior/samples/{{dataset}}_{{repr}}_{{fold}}_unique_masses.csv.gz",
        reference_file=f"{OUTPUT_DIR}/{{enum_factor}}/prior/inputs/train0_{{dataset}}_{{repr}}_{{fold}}.smi",
        pubchem_file=PATHS['pubchem_tsv_file'],
    output:
        output_file=f"{OUTPUT_DIR}/model_evaluation/{{enum_factor}}/{{dataset}}_{{repr}}_{{fold}}_write_nn_tc.csv.gz",
    resources:
        mem_mb=64000,
        runtime=1000,
    shell:
        'clm write_nn_Tc '
        '--query_file {input.query_file} '
        '--reference_file {input.reference_file} '
        '--pubchem_file {input.pubchem_file} '
        '--max_molecules 50000 '
        '--output_file {output.output_file} '


rule plot_write_nn_tc:
    conda: "clm"
    input:
        expand(f"{OUTPUT_DIR}/model_evaluation/{{enum_factor}}/{{dataset}}_{{repr}}_{{fold}}_write_nn_tc.csv.gz",
            dataset=DATASET, repr=REPRESENTATIONS, fold=range(FOLDS), allow_missing=True)
    output:
        directory(f"{OUTPUT_DIR}/model_evaluation/plot/{{enum_factor}}/write_nn_tc"),
    resources:
        mem_mb=256000,
        runtime=1000,
    shell:
        'clm plot write_nn_tc '
        '--outcome_files {input} '
        '--output_dir {output} '



rule train_discriminator:
    conda: "clm"
    input:
        train_file=f"{OUTPUT_DIR}/{{enum_factor}}/prior/inputs/train0_{{dataset}}_{{repr}}_{{fold}}.smi",
        sampled_file=f"{OUTPUT_DIR}/{{enum_factor}}/prior/samples/{{dataset}}_{{repr}}_{{fold}}_unique_masses.csv.gz",
    output:
        output_file=f"{OUTPUT_DIR}/model_evaluation/{{enum_factor}}/{{dataset}}_{{repr}}_{{fold}}_train_discriminator.csv.gz",
    resources:
        mem_mb=64000,
        runtime=1000,
    shell:
        'clm train_discriminator '
        '--train_file {input.train_file} '
        '--sampled_file {input.sampled_file} '
        '--output_file {output.output_file} '


rule plot_train_discriminator:
    conda: "clm"
    input:
        expand(f"{OUTPUT_DIR}/model_evaluation/{{enum_factor}}/{{dataset}}_{{repr}}_{{fold}}_train_discriminator.csv.gz",
            dataset=DATASET, repr=REPRESENTATIONS, fold=range(FOLDS), allow_missing=True)
    output:
        directory(f"{OUTPUT_DIR}/model_evaluation/plot/{{enum_factor}}/train_discriminator"),
    resources:
        mem_mb=256000,
        runtime=1000,
    shell:
        'clm plot train_discriminator '
        '--outcome_files {input} '
        '--output_dir {output} '


rule freq_distribution:
    conda: "clm"
    input:
        sampled_file=f"{OUTPUT_DIR}/{{enum_factor}}/prior/samples/{{dataset}}_{{repr}}_{{fold}}_unique_masses.csv.gz",
        test_file=f"{OUTPUT_DIR}/{{enum_factor}}/prior/inputs/test0_{{dataset}}_{{repr}}_{{fold}}.smi",
    output:
        output_file=f"{OUTPUT_DIR}/model_evaluation/{{enum_factor}}/{{dataset}}_{{repr}}_{{fold}}_freq_distribution.csv.gz",
    resources:
        mem_mb=64000,
        runtime=1000,
    shell:
        'clm write_freq_distribution '
        '--sampled_file {input.sampled_file} '
        '--test_file {input.test_file} '
        '--output_file {output.output_file} '


rule plot_freq_distribution:
    conda: "clm"
    input:
        expand(f"{OUTPUT_DIR}/model_evaluation/{{enum_factor}}/{{dataset}}_{{repr}}_{{fold}}_freq_distribution.csv.gz",
            dataset=DATASET, repr=REPRESENTATIONS, fold=range(FOLDS), allow_missing=True)
    output:
        directory(f"{OUTPUT_DIR}/model_evaluation/plot/{{enum_factor}}/freq_distribution"),
    resources:
        mem_mb=256000,
        runtime=1000,
    shell:
        'clm plot freq_distribution '
        '--outcome_files {input} '
        '--output_dir {output} '


rule calculate_outcome_distrs:
    conda: "clm"
    input:
        sample_file=f"{OUTPUT_DIR}/{{enum_factor}}/prior/samples/{{dataset}}_{{repr}}_{{fold}}_unique_masses.csv.gz",
        train_file=f"{OUTPUT_DIR}/{{enum_factor}}/prior/inputs/train0_{{dataset}}_{{repr}}_{{fold}}.smi",
        pubchem_file=PATHS['pubchem_tsv_file'],
    output:
        output_file=f"{OUTPUT_DIR}/model_evaluation/{{enum_factor}}/{{dataset}}_{{repr}}_{{fold}}_calculate_outcome_distrs.csv.gz",
    resources:
        mem_mb=64000,
        runtime=1000,
    shell:
        'clm calculate_outcome_distrs '
        '--sample_file {input.sample_file} '
        '--train_file {input.train_file} '
        '--pubchem_file {input.pubchem_file} '
        '--max_mols 100000 '
        '--output_file {output.output_file} '


rule plot_outcome_distributions:
    conda: "clm"
    input:
        expand(f"{OUTPUT_DIR}/model_evaluation/{{enum_factor}}/{{dataset}}_{{repr}}_{{fold}}_calculate_outcome_distrs.csv.gz",
            dataset=DATASET, repr=REPRESENTATIONS, fold=range(FOLDS), allow_missing=True)
    output:
        directory(f"{OUTPUT_DIR}/model_evaluation/plot/{{enum_factor}}/calculate_outcome_distrs"),
    resources:
        mem_mb=256000,
        runtime=1000,
    shell:
        'clm plot calculate_outcome_distrs '
        '--outcome_files {input} '
        '--output_dir {output} '

rule nn_tc_ever_v_never:
    conda: "clm"
    input:
        query_file=f"{OUTPUT_DIR}/{{enum_factor}}/prior/inputs/train0_{{dataset}}_{{repr}}_{{fold}}.smi",
        reference_file=f"{OUTPUT_DIR}/{{enum_factor}}/prior/inputs/train0_{{dataset}}_{{repr}}_{{fold}}.smi",
    output:
        output_file=f"{OUTPUT_DIR}/model_evaluation/{{enum_factor}}/{{dataset}}_{{repr}}_{{fold}}_nn_tc_ever_v_never.csv.gz",
    resources:
        mem_mb=64000,
        runtime=1000,
    shell:
        'clm write_nn_Tc '
        '--query_file {input.query_file} '
        '--reference_file {input.reference_file} '
        '--output_file {output.output_file} '


rule plot_nn_tc_ever_v_never:
    conda: "clm"
    input:
        nn_tc_file = expand(f"{OUTPUT_DIR}/model_evaluation/{{enum_factor}}/{{dataset}}_{{repr}}_{{fold}}_nn_tc_ever_v_never.csv.gz",
            dataset=DATASET, repr=REPRESENTATIONS, fold=range(FOLDS), allow_missing=True),
        ranks_file = expand(f"{OUTPUT_DIR}/{{enum_factor}}/prior/structural_prior/{{dataset}}_{{repr}}_min1_all_freq-avg_CV_ranks_structure.csv.gz",
            dataset=DATASET, repr=REPRESENTATIONS, allow_missing=True)
    output:
        directory(f"{OUTPUT_DIR}/model_evaluation/plot/{{enum_factor}}/nn_tc_ever_v_never"),
    resources:
        mem_mb=256000,
        runtime=1000,
    shell:
        'clm plot nn_tc_ever_v_never '
        '--outcome_files {input.nn_tc_file} '
        '--ranks_file {input.ranks_file} '
        '--output_dir {output} '


rule plot_topk_tc:
    conda: "clm"
    input:
        expand(f"{OUTPUT_DIR}/{{enum_factor}}/prior/structural_prior/{{dataset}}_{{repr}}_min1_all_freq-avg_CV_tc.csv.gz",
            dataset=DATASET, repr=REPRESENTATIONS, allow_missing=True)
    output:
        directory(f"{OUTPUT_DIR}/model_evaluation/plot/{{enum_factor}}/topk_tc"),
    resources:
        mem_mb=256000,
        runtime=1000,
    shell:
        'clm plot topk_tc '
        '--outcome_files {input} '
        '--output_dir {output} '


rule forecast:
    conda: "clm"
    input:
        test_file=f"{OUTPUT_DIR}/{{enum_factor}}/prior/inputs/test0_{{dataset}}_{{repr}}_{{fold}}.smi",
        sample_file=f"{OUTPUT_DIR}/{{enum_factor}}/prior/samples/{{dataset}}_{{repr}}_{{fold}}_unique_masses.csv.gz",
    output:
        output_file=f"{OUTPUT_DIR}/model_evaluation/{{enum_factor}}/{{dataset}}_{{repr}}_{{fold}}_forecast.csv",
    resources:
        mem_mb=64000,
        runtime=30,
    shell:
        'clm forecast '
        '--test_file {input.test_file} '
        '--sample_file {input.sample_file} '
        '--output_file {output.output_file} '


rule plot_topk:
    conda: "clm"
    input:
        expand(f"{OUTPUT_DIR}/{{enum_factor}}/prior/structural_prior/{{dataset}}_{{repr}}_min1_all_freq-avg_CV_ranks_structure.csv.gz",
            dataset=DATASET, repr=REPRESENTATIONS, allow_missing=True)
    output:
        directory(f"{OUTPUT_DIR}/model_evaluation/plot/{{enum_factor}}/topk"),
    resources:
        mem_mb=256000,
        runtime=1000,
    shell:
        'clm plot topk '
        '--outcome_files {input} '
        '--output_dir {output} '
