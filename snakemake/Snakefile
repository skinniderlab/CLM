configfile: "config.json"
threads: 1
# -----------------------------------------------------------------------------
# Setup
# -----------------------------------------------------------------------------
DATASETS = config["datasets"]
REPRESENTATIONS = config["representations"]
SAMPLE_IDXS = config["sample_idxs"]
K = config["k"]
OUTPUT_DIR = config['output_dir']
MODEL_PARAMS = config['model_params']

shell.executable("/bin/bash")

wildcard_constraints:
    dataset="|".join(DATASETS)


# -----------------------------------------------------------------------------

# -----------------------------------------------------------------------------
# Rules
# -----------------------------------------------------------------------------
rule all:
    input:
        output_file = expand(f"{OUTPUT_DIR}/prior/samples/{{dataset}}_{{repr}}_sample{{sample_idx}}_{{fold}}_sample_1.csv",
         dataset=DATASETS, repr=REPRESENTATIONS, sample_idx=SAMPLE_IDXS, fold=range(1, K + 1)),
        time_file = expand(f"{OUTPUT_DIR}/prior/samples/{{dataset}}_{{repr}}_sample{{sample_idx}}_{{fold}}_timing_1.csv",
         dataset=DATASETS, repr=REPRESENTATIONS, sample_idx=SAMPLE_IDXS, fold=range(1, K + 1)),
        nvstat_file = expand(f"{OUTPUT_DIR}/prior/samples/{{dataset}}_{{repr}}_sample{{sample_idx}}_{{fold}}.nvstat",
         dataset=DATASETS, repr=REPRESENTATIONS, sample_idx=SAMPLE_IDXS, fold=range(1, K + 1))


rule generate_prior_inputs:
    input:
        f"{OUTPUT_DIR}/prior/raw/{{dataset}}.txt"
    output:
        train_file=f"{OUTPUT_DIR}/prior/inputs/train_{{dataset}}_{{repr}}_sample{{sample_idx}}_{{fold}}.csv",
        vocab_file=f"{OUTPUT_DIR}/prior/inputs/train_{{dataset}}_{{repr}}_sample{{sample_idx}}_{{fold}}.vocabulary",
        test_file=f"{OUTPUT_DIR}/prior/inputs/test_{{dataset}}_{{repr}}_sample{{sample_idx}}_{{fold}}.csv"
    shell: """
        python ../python/inner-preprocess-prior-datasets.py \
        --representation {wildcards.repr} \
        --enum_factor 0 \
        --sample_idx {wildcards.sample_idx} \
        --k {K} \
        --cv_fold {wildcards.fold} \
        --input_file {input} \
        --train_file {output.train_file} \
        --vocab_file {output.vocab_file} \
        --test_file {output.test_file}
        """


rule inner_create_training_sets:
    input:
        f"{OUTPUT_DIR}/prior/raw/"
    output:
        output_file=f"{OUTPUT_DIR}/prior/training/{{dataset}}_{{repr}}_sample{{sample_idx}}_{{fold}}_SMILES.smi",
        vocab_file=f"{OUTPUT_DIR}/prior/training/train_{{dataset}}_{{repr}}_sample{{sample_idx}}_{{fold}}.vocabulary"
    shell:
        'python ../python/inner-create-training-sets.py '
        '--input_dir {input} '
        '--database {wildcards.dataset} '
        '--representation {wildcards.repr} '
        '--enum_factor {MODEL_PARAMS[enum_factor]} '
        '--n_molecules {MODEL_PARAMS[n_molecules]} '
        '--min_tc {MODEL_PARAMS[min_tc]} '
        '--sample_idx {wildcards.sample_idx} '
        '--output_file {output.output_file} '
        '--vocab_file {output.vocab_file} '


rule inner_train_models_RNN:
    input:
        input_file=f"{OUTPUT_DIR}/prior/inputs/train_{{dataset}}_{{repr}}_sample{{sample_idx}}_{{fold}}.csv",
        vocab_file=f"{OUTPUT_DIR}/prior/inputs/train_{{dataset}}_{{repr}}_sample{{sample_idx}}_{{fold}}.vocabulary"
    output:
        smiles_file=f"{OUTPUT_DIR}/prior/models/{{dataset}}_{{repr}}_sample{{sample_idx}}_{{fold}}_SMILES.smi",
        model_file=f"{OUTPUT_DIR}/prior/models/{{dataset}}_{{repr}}_sample{{sample_idx}}_{{fold}}_model.pt",
        loss_file=f"{OUTPUT_DIR}/prior/models/{{dataset}}_{{repr}}_sample{{sample_idx}}_{{fold}}_loss.csv",
        time_file=f"{OUTPUT_DIR}/prior/models/{{dataset}}_{{repr}}_sample{{sample_idx}}_{{fold}}_timing.csv"
    shell:
            'python ../python/inner-train-models-RNN.py '
            '--database {wildcards.dataset} '
            '--representation {wildcards.repr} '
            '--enum_factor {MODEL_PARAMS[enum_factor]} '
            '--n_molecules {MODEL_PARAMS[n_molecules]} '
            '--min_tc {MODEL_PARAMS[min_tc]} '
            '--sample_idx {wildcards.sample_idx} '
            '--rnn_type {MODEL_PARAMS[rnn_type]} '
            '--embedding_size {MODEL_PARAMS[embedding_size]} '
            '--hidden_size {MODEL_PARAMS[hidden_size]} '
            '--n_layers {MODEL_PARAMS[n_layers]} '
            '--dropout {MODEL_PARAMS[dropout]} '
            '--batch_size {MODEL_PARAMS[batch_size]} '
            '--learning_rate {MODEL_PARAMS[learning_rate]} '
            '--max_epochs {MODEL_PARAMS[max_epochs]} '
            '--patience {MODEL_PARAMS[patience]} '
            '--log_every_steps {MODEL_PARAMS[log_every_steps]} '
            '--log_every_epochs {MODEL_PARAMS[log_every_epochs]} '
            '--sample_mols {MODEL_PARAMS[sample_mols]} '
            '--input_file {input.input_file} '
            '--vocab_file {input.vocab_file} '
            '--smiles_file {output.smiles_file} '
            '--model_file {output.model_file} '
            '--loss_file {output.loss_file} '
            '--time_file {output.time_file} '


rule inner_sample_molecules_RNN:
    input:
        input_file=f"{OUTPUT_DIR}/prior/models/{{dataset}}_{{repr}}_sample{{sample_idx}}_{{fold}}_SMILES.smi",
        vocab_file=f"{OUTPUT_DIR}/prior/inputs/train_{{dataset}}_{{repr}}_sample{{sample_idx}}_{{fold}}.vocabulary",
        model_file=f"{OUTPUT_DIR}/prior/models/{{dataset}}_{{repr}}_sample{{sample_idx}}_{{fold}}_model.pt",
        check_file=f"{OUTPUT_DIR}/prior/models/{{dataset}}_{{repr}}_sample{{sample_idx}}_{{fold}}_timing.csv"
    output:
        output_file=f"{OUTPUT_DIR}/prior/samples/{{dataset}}_{{repr}}_sample{{sample_idx}}_{{fold}}_sample_1.csv",
        time_file=f"{OUTPUT_DIR}/prior/samples/{{dataset}}_{{repr}}_sample{{sample_idx}}_{{fold}}_timing_1.csv",
        nvstat_file=f"{OUTPUT_DIR}/prior/samples/{{dataset}}_{{repr}}_sample{{sample_idx}}_{{fold}}.nvstat"
    shell:
        'python ../python/inner-sample-molecules-RNN.py '
        '--database {wildcards.dataset} '
        '--representation {wildcards.repr} '
        '--enum_factor {MODEL_PARAMS[enum_factor]} '
        '--n_molecules {MODEL_PARAMS[n_molecules]} '
        '--min_tc {MODEL_PARAMS[min_tc]} '
        '--sample_idx {wildcards.sample_idx} '
        '--rnn_type {MODEL_PARAMS[rnn_type]} '
        '--embedding_size {MODEL_PARAMS[embedding_size]} '
        '--hidden_size {MODEL_PARAMS[hidden_size]} '
        '--n_layers {MODEL_PARAMS[n_layers]} '
        '--dropout {MODEL_PARAMS[dropout]} '
        '--batch_size {MODEL_PARAMS[batch_size]} '
        '--learning_rate {MODEL_PARAMS[learning_rate]} '
        '--mol_sample_idx {wildcards.sample_idx} '
        '--sample_mols {MODEL_PARAMS[sample_mols]} '
        '--input_file {input.input_file} '
        '--vocab_file {input.vocab_file} '
        '--model_file {input.model_file} '
        '--check_file {input.check_file} '
        '--output_file {output.output_file} '
        '--time_file {output.time_file} '
        '--nvstat_file {output.nvstat_file} '

# -----------------------------------------------------------------------------
